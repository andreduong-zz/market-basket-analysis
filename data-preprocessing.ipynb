{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Market Basket Analysis with SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whether you shop from meticulously planned grocery lists or let whimsy guide your grazing, our unique food rituals define who we are. Instacart, a grocery ordering and delivery app, aims to make it easy to fill your refrigerator and pantry with your personal favorites and staples when you need them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I will use this anonymized data from Instacart on customer orders over time to predict which previously purchased products will be in a userâ€™s next order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What I Have Learned From This Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SQLAlchemy<br>\n",
    "* SQL queries: CREATE, SELECT, FROM, JOIN, DROP, INNER JOIN, etc.<br>\n",
    "* Using PostgreSQL database<br>\n",
    "* Association rule<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset for this competition is a relational set of files describing customers' orders over time. The goal of the competition is to predict which products will be in a user's next order. The dataset is anonymized and contains a sample of over 3 million grocery orders from more than 200,000 Instacart users. For each user, we provide between 4 and 100 of their orders, with the sequence of products purchased in each order. We also provide the week and hour of day the order was placed, and a relative measure of time between orders. Each entity (customer, product, order, aisle, etc.) has an associated unique id. Most of the files and variable names should be self-explanatory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More information about this dataset can be found [here](https://www.kaggle.com/c/instacart-market-basket-analysis/data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data into PostgreSQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T14:01:00.455554Z",
     "start_time": "2019-08-05T14:00:59.288807Z"
    }
   },
   "outputs": [],
   "source": [
    "# import necessary tools \n",
    "from sqlalchemy import create_engine\n",
    "import sql\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T14:01:00.472676Z",
     "start_time": "2019-08-05T14:01:00.461825Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/andreduong/market-basket-analysis\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T14:01:00.515880Z",
     "start_time": "2019-08-05T14:01:00.502809Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = '/Users/andreduong/market-basket-analysis'\n",
    "data_output = '/Users/andreduong/market-basket-analysis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T14:01:00.920539Z",
     "start_time": "2019-08-05T14:01:00.887265Z"
    }
   },
   "outputs": [],
   "source": [
    "from subprocess import check_output\n",
    "\n",
    "conn = create_engine('postgresql:///instacart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T14:01:01.474581Z",
     "start_time": "2019-08-05T14:01:01.460291Z"
    }
   },
   "outputs": [],
   "source": [
    "# read chunk to postgres\n",
    "# this python script is influenced by https://gist.github.com/olgabradford/f04f23692c78fc0beb377894ce5e5e59\n",
    "def read_chunk_csv_to_psql(file_name, disk_engine, table):\n",
    "    # to time loading process\n",
    "    start = datetime.now()\n",
    "    # chunk_size - number of rows\n",
    "    chunk_size = 10000\n",
    "    i = 0\n",
    "    index_start = 1\n",
    "    drop_table = \"DROP TABLE IF EXISTS %s ;\" %(table)\n",
    "    conn.execute(drop_table)        \n",
    "    \n",
    "    for df in pd.read_csv(file_name, chunksize=chunk_size, iterator=True, encoding='utf-8'):\n",
    "        df = df.rename(columns = {c: c.replace(' ', '') for c in df.columns}) # delete spaces between columns from CSV file\n",
    "        df.index += index_start\n",
    "        i += 1\n",
    "        if i <= 50:\n",
    "            df.to_sql(table, disk_engine, if_exists = 'append')\n",
    "            if i%10 == 0:\n",
    "                #print how long it takes to load database\n",
    "                print ('{} Seconds: Loaded rows {}'.format((datetime.now() - start).total_seconds(), i*chunk_size))\n",
    "            index_start = df.index[-1] + 1\n",
    "        else:\n",
    "            print(\"Limit Data for exploration\")\n",
    "            break\n",
    "    \n",
    "    # created indexes on all id columns\n",
    "    index_columns = [col for col in df.columns if col.find(\"_id\") > -1]\n",
    "    for col in index_columns:\n",
    "        # create indexes for latter for quicker access\n",
    "        create_indexes = \"CREATE INDEX index_%s on %s (%s);\" %(col+ \"_\" + table, table, col)\n",
    "        conn.execute(create_indexes)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T14:01:02.238205Z",
     "start_time": "2019-08-05T14:01:02.227123Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/andreduong/market-basket-analysis\n",
      "['products.csv', 'orders.csv', 'order_products__train.csv', 'departments.csv', 'aisles.csv', 'order_products__prior.csv', 'sample_submission.csv']\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "files_list = [file for file in os.listdir() if file.find(\".csv\") != -1]\n",
    "print(files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T14:06:24.186193Z",
     "start_time": "2019-08-05T14:01:03.085636Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loading table products\n",
      "loading of table products complete\n",
      "\n",
      "loading table orders\n",
      "17.615521 Seconds: Loaded rows 100000\n",
      "37.885305 Seconds: Loaded rows 200000\n",
      "69.787772 Seconds: Loaded rows 300000\n",
      "94.289425 Seconds: Loaded rows 400000\n",
      "117.934345 Seconds: Loaded rows 500000\n",
      "Limit Data for exploration\n",
      "loading of table orders complete\n",
      "\n",
      "loading table order_products__train\n",
      "22.270205 Seconds: Loaded rows 100000\n",
      "40.803577 Seconds: Loaded rows 200000\n",
      "59.619467 Seconds: Loaded rows 300000\n",
      "79.089541 Seconds: Loaded rows 400000\n",
      "95.195659 Seconds: Loaded rows 500000\n",
      "Limit Data for exploration\n",
      "loading of table order_products__train complete\n",
      "\n",
      "loading table departments\n",
      "loading of table departments complete\n",
      "\n",
      "loading table aisles\n",
      "loading of table aisles complete\n",
      "\n",
      "loading table order_products__prior\n",
      "17.48114 Seconds: Loaded rows 100000\n",
      "33.202361 Seconds: Loaded rows 200000\n",
      "51.615399 Seconds: Loaded rows 300000\n",
      "67.736884 Seconds: Loaded rows 400000\n",
      "85.495928 Seconds: Loaded rows 500000\n",
      "Limit Data for exploration\n",
      "loading of table order_products__prior complete\n",
      "\n",
      "loading table sample_submission\n",
      "loading of table sample_submission complete\n"
     ]
    }
   ],
   "source": [
    "for file in files_list:    \n",
    "    table = file.split(\".\")[0]\n",
    "    print('\\nloading table {}'.format(table))\n",
    "    file_name = file\n",
    "    read_chunk_csv_to_psql(file_name,conn,table)\n",
    "    print ('loading of table {} complete'.format(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's take a look at each table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## aisles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T14:07:44.054374Z",
     "start_time": "2019-08-05T14:07:44.025792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 in aisles table:\n",
      "    index  aisle_id                       aisle\n",
      "0      1         1       prepared soups salads\n",
      "1      2         2           specialty cheeses\n",
      "2      3         3         energy granola bars\n",
      "3      4         4               instant foods\n",
      "4      5         5  marinades meat preparation\n"
     ]
    }
   ],
   "source": [
    "aisles = pd.read_sql_query(\"SELECT * FROM aisles LIMIT 5;\", conn)\n",
    "print(\"Top 5 in aisles table:\\n\", aisles.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## departments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T14:07:45.998928Z",
     "start_time": "2019-08-05T14:07:45.979141Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 in departments table:\n",
      "    index  department_id department\n",
      "0      1              1     frozen\n",
      "1      2              2      other\n",
      "2      3              3     bakery\n",
      "3      4              4    produce\n",
      "4      5              5    alcohol\n"
     ]
    }
   ],
   "source": [
    "departments = pd.read_sql_query(\"SELECT * FROM departments LIMIT 5;\", conn)\n",
    "print(\"Top 5 in departments table:\\n\", departments.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T14:07:49.420328Z",
     "start_time": "2019-08-05T14:07:49.394046Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 in products table:\n",
      "    index  product_id                                       product_name  \\\n",
      "0      1           1                         Chocolate Sandwich Cookies   \n",
      "1      2           2                                   All-Seasons Salt   \n",
      "2      3           3               Robust Golden Unsweetened Oolong Tea   \n",
      "3      4           4  Smart Ones Classic Favorites Mini Rigatoni Wit...   \n",
      "4      5           5                          Green Chile Anytime Sauce   \n",
      "\n",
      "   aisle_id  department_id  \n",
      "0        61             19  \n",
      "1       104             13  \n",
      "2        94              7  \n",
      "3        38              1  \n",
      "4         5             13  \n"
     ]
    }
   ],
   "source": [
    "products = pd.read_sql_query(\"SELECT * FROM products LIMIT 5;\", conn)\n",
    "print(\"Top 5 in products table:\\n\", products.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T14:08:23.324708Z",
     "start_time": "2019-08-05T14:08:23.300834Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 in orders table:\n",
      "    index  order_id  user_id eval_set  order_number  order_dow  \\\n",
      "0      1   2539329        1    prior             1          2   \n",
      "1      2   2398795        1    prior             2          3   \n",
      "2      3    473747        1    prior             3          3   \n",
      "3      4   2254736        1    prior             4          4   \n",
      "4      5    431534        1    prior             5          4   \n",
      "\n",
      "   order_hour_of_day  days_since_prior_order  \n",
      "0                  8                     NaN  \n",
      "1                  7                    15.0  \n",
      "2                 12                    21.0  \n",
      "3                  7                    29.0  \n",
      "4                 15                    28.0  \n"
     ]
    }
   ],
   "source": [
    "orders = pd.read_sql_query(\"SELECT * FROM orders LIMIT 5;\", conn)\n",
    "print(\"Top 5 in orders table:\\n\", orders.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## order_products__train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T14:10:54.130827Z",
     "start_time": "2019-08-05T14:10:54.112285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 in orders train table:\n",
      "    index  order_id  product_id  add_to_cart_order  reordered\n",
      "0      1         1       49302                  1          1\n",
      "1      2         1       11109                  2          1\n",
      "2      3         1       10246                  3          0\n",
      "3      4         1       49683                  4          0\n",
      "4      5         1       43633                  5          1\n"
     ]
    }
   ],
   "source": [
    "orders_train = pd.read_sql_query(\"SELECT * FROM order_products__train LIMIT 5;\", conn)\n",
    "print(\"Top 5 in orders train table:\\n\", orders_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## order_products__prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T14:11:40.080607Z",
     "start_time": "2019-08-05T14:11:40.063859Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 in orders prior table:\n",
      "    index  order_id  product_id  add_to_cart_order  reordered\n",
      "0      1         2       33120                  1          1\n",
      "1      2         2       28985                  2          1\n",
      "2      3         2        9327                  3          0\n",
      "3      4         2       45918                  4          1\n",
      "4      5         2       30035                  5          0\n"
     ]
    }
   ],
   "source": [
    "orders_prior = pd.read_sql_query(\"SELECT * FROM order_products__prior LIMIT 5;\", conn)\n",
    "print(\"Top 5 in orders prior table:\\n\", orders_prior.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T14:12:18.785979Z",
     "start_time": "2019-08-05T14:12:18.777827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All loaded successfully. Now we can delete temporary dataframes.\n"
     ]
    }
   ],
   "source": [
    "print(\"All loaded successfully. Now we can delete temporary dataframes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T14:12:34.826524Z",
     "start_time": "2019-08-05T14:12:34.815471Z"
    }
   },
   "outputs": [],
   "source": [
    "del aisles, departments, products, orders, orders_train, orders_prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## department, aisle and products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T14:18:00.316856Z",
     "start_time": "2019-08-05T14:18:00.091355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for productscombined: 0.1987\n",
      "\n",
      "Top 5 in productscombined:\n",
      "    index  product_id                                       product_name  \\\n",
      "0      1           1                         Chocolate Sandwich Cookies   \n",
      "1      2           2                                   All-Seasons Salt   \n",
      "2      3           3               Robust Golden Unsweetened Oolong Tea   \n",
      "3      4           4  Smart Ones Classic Favorites Mini Rigatoni Wit...   \n",
      "4      5           5                          Green Chile Anytime Sauce   \n",
      "\n",
      "   aisle_id  department_id department                       aisle  \n",
      "0        61             19     snacks               cookies cakes  \n",
      "1       104             13     pantry           spices seasonings  \n",
      "2        94              7  beverages                         tea  \n",
      "3        38              1     frozen                frozen meals  \n",
      "4         5             13     pantry  marinades meat preparation  \n",
      "\n",
      "Total number of products in database: \n",
      "    count\n",
      "0  49688\n"
     ]
    }
   ],
   "source": [
    "# merge tables department, aisle, products, and call it productscombined\n",
    "# add a time counter\n",
    "start_time1 = datetime.now()\n",
    "\n",
    "drop_productscombined_table = \"\"\" DROP TABLE IF EXISTS productscombined;\"\"\"\n",
    "conn.execute(drop_productscombined_table)\n",
    "joinprod_sql = \"\"\"\\\n",
    "    CREATE TABLE productscombined AS\n",
    "    SELECT p.*, d.department, a.aisle\n",
    "    FROM products p\n",
    "    INNER JOIN departments d ON p.department_id = d.department_id\n",
    "    INNER JOIN aisles a ON p.aisle_id = a.aisle_id;\n",
    "    \"\"\"\n",
    "conn.execute(joinprod_sql)\n",
    "\n",
    "# load first 5 rows\n",
    "productscombined_qc = pd.read_sql_query(\"SELECT * FROM productscombined LIMIT 5;\", conn)\n",
    "\n",
    "end_time1 = datetime.now()\n",
    "\n",
    "print('Time for productscombined: {}\\n'.format((end_time1 - start_time1).total_seconds()))\n",
    "print(\"Top 5 in productscombined:\\n\", productscombined_qc.head())\n",
    "\n",
    "count_merge1 = pd.read_sql_query(\"SELECT COUNT(product_id) FROM productscombined;\", conn)\n",
    "print(\"\\nTotal number of products in database: \\n\", count_merge1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## order_products_prior and orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T14:21:55.389869Z",
     "start_time": "2019-08-05T14:21:54.504953Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for orderscombined1: 0.822446\n",
      "\n",
      "Top 5 orderscombined1 table: \n",
      "      index  order_id  user_id eval_set  order_number  order_dow  \\\n",
      "0  7400621         6    22352    prior             4          1   \n",
      "1  7400621         6    22352    prior             4          1   \n",
      "2  7400621         6    22352    prior             4          1   \n",
      "3   200029         8     3107    prior             5          4   \n",
      "4  4951076        14    18194    prior            49          3   \n",
      "\n",
      "   order_hour_of_day  days_since_prior_order  product_id  add_to_cart_order  \\\n",
      "0                 12                    30.0       40462                  1   \n",
      "1                 12                    30.0       15873                  2   \n",
      "2                 12                    30.0       41897                  3   \n",
      "3                  6                    17.0       23423                  1   \n",
      "4                 15                     3.0       20392                  1   \n",
      "\n",
      "   reordered  \n",
      "0          0  \n",
      "1          0  \n",
      "2          0  \n",
      "3          1  \n",
      "4          1  \n",
      "\n",
      "Total number of products in orders in database \n",
      "    count\n",
      "0  72909\n"
     ]
    }
   ],
   "source": [
    "start_time2 = datetime.now()\n",
    "\n",
    "drop_orderscombined1_table=\"\"\" DROP TABLE IF EXISTS orderscombined1;\"\"\"\n",
    "conn.execute(drop_orderscombined1_table)\n",
    "joinordersprior_sql1 = \"\"\"\\\n",
    "    CREATE TABLE orderscombined1 AS\n",
    "    SELECT o.*, op.product_id, op.add_to_cart_order,op.reordered\n",
    "    FROM orders o\n",
    "    INNER JOIN order_products__prior op ON o.order_id = op.order_id;\n",
    "    \"\"\"\n",
    "conn.execute(joinordersprior_sql1)\n",
    "\n",
    "# load top 5\n",
    "orderscombined1 = pd.read_sql_query(\"SELECT * FROM orderscombined1 LIMIT 5;\", conn)\n",
    "\n",
    "# create indexes to do requests much faster\n",
    "indexcolumns = [col for col in orderscombined1.columns if col.find(\"_id\")>-1]\n",
    "for col in indexcolumns:\n",
    "    createindexes = \"CREATE INDEX index_%s ON orderscombined1 (%s);\" % (col + \"_orderscombined1\", col)\n",
    "    conn.execute(createindexes)         \n",
    "        \n",
    "end_time2 = datetime.now()\n",
    "print('\\nTime for orderscombined1: {}\\n'.format((end_time2-start_time2).total_seconds()))\n",
    "print(\"Top 5 orderscombined1 table: \\n\", orderscombined1.head())\n",
    "\n",
    "count_merge1 = pd.read_sql_query(\"SELECT COUNT(product_id) FROM orderscombined1;\", conn)\n",
    "print(\"\\nTotal number of products in orders in database \\n\", count_merge1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## orders and the order_products__train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T14:22:24.826059Z",
     "start_time": "2019-08-05T14:22:23.607041Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for orderscombined2: 1.187384\n",
      "\n",
      "Top 5 orderscombined2 table: \n",
      "      index  order_id  user_id eval_set  order_number  order_dow  \\\n",
      "0  4344949        96    17227    train             7          6   \n",
      "1  4344949        96    17227    train             7          6   \n",
      "2  4344949        96    17227    train             7          6   \n",
      "3  4344949        96    17227    train             7          6   \n",
      "4  4344949        96    17227    train             7          6   \n",
      "\n",
      "   order_hour_of_day  days_since_prior_order  product_id  add_to_cart_order  \\\n",
      "0                 20                    30.0       20574                  1   \n",
      "1                 20                    30.0       30391                  2   \n",
      "2                 20                    30.0       40706                  3   \n",
      "3                 20                    30.0       25610                  4   \n",
      "4                 20                    30.0       27966                  5   \n",
      "\n",
      "   reordered  \n",
      "0          1  \n",
      "1          0  \n",
      "2          1  \n",
      "3          0  \n",
      "4          1  \n",
      "\n",
      "Total number of products in orders in database \n",
      "    count\n",
      "0  73575\n"
     ]
    }
   ],
   "source": [
    "start_time3 = datetime.now()\n",
    "\n",
    "drop_orderscombined2_table=\"\"\" DROP TABLE IF EXISTS orderscombined2;\"\"\"\n",
    "conn.execute(drop_orderscombined2_table)\n",
    "joinordersprior_sql2 = \"\"\"\\\n",
    "    CREATE TABLE orderscombined2 AS\n",
    "    SELECT o.*, op.product_id, op.add_to_cart_order,op.reordered\n",
    "    FROM orders o\n",
    "    INNER JOIN order_products__train op ON o.order_id = op.order_id;\n",
    "    \"\"\"\n",
    "\n",
    "conn.execute(joinordersprior_sql2)\n",
    "# load top 5\n",
    "orderscombined2 = pd.read_sql_query(\"SELECT * FROM orderscombined2 LIMIT 5;\", conn)\n",
    "\n",
    "#create indexes to do requests much faster\n",
    "indexcolumns = [col for col in orderscombined2.columns if col.find(\"_id\") > -1]\n",
    "for col in indexcolumns:\n",
    "    createindexes = \"CREATE INDEX index_%s ON orderscombined2 (%s);\" %(col + \"_orderscombined2\", col)\n",
    "    conn.execute(createindexes)              \n",
    "        \n",
    "end_time3 = datetime.now()\n",
    "print('\\nTime for orderscombined2: {}\\n'.format((end_time3-start_time3).total_seconds()))\n",
    "print(\"Top 5 orderscombined2 table: \\n\", orderscombined2.head())\n",
    "\n",
    "count_merge2 = pd.read_sql_query(\"SELECT COUNT (user_id) FROM orderscombined2 ;\", conn)\n",
    "print(\"\\nTotal number of products in orders in database \\n\", count_merge2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge all tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T14:34:21.098795Z",
     "start_time": "2019-08-05T14:34:20.052137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for prioralldata table: 0.978575\n",
      "\n",
      "Prioralldata table: \n",
      "      index  order_id  user_id eval_set  order_number  order_dow  \\\n",
      "0   200029         8     3107    prior             5          4   \n",
      "1  4951076        14    18194    prior            49          3   \n",
      "2  4951076        14    18194    prior            49          3   \n",
      "3  4951076        14    18194    prior            49          3   \n",
      "4  4951076        14    18194    prior            49          3   \n",
      "\n",
      "   order_hour_of_day  days_since_prior_order  product_id  add_to_cart_order  \\\n",
      "0                  6                    17.0       23423                  1   \n",
      "1                 15                     3.0       20392                  1   \n",
      "2                 15                     3.0       27845                  2   \n",
      "3                 15                     3.0         162                  3   \n",
      "4                 15                     3.0        2452                  4   \n",
      "\n",
      "   reordered                    product_name  department  \\\n",
      "0          1   Original Hawaiian Sweet Rolls      bakery   \n",
      "1          1   Hair Bender Whole Bean Coffee   beverages   \n",
      "2          1              Organic Whole Milk  dairy eggs   \n",
      "3          1  Organic Mini Homestyle Waffles      frozen   \n",
      "4          1        Naturals Chicken Nuggets      frozen   \n",
      "\n",
      "                     aisle  \n",
      "0               buns rolls  \n",
      "1                   coffee  \n",
      "2                     milk  \n",
      "3         frozen breakfast  \n",
      "4  frozen appetizers sides  \n",
      "\n",
      "Count orders prior table:\n",
      "    count\n",
      "0  72909\n"
     ]
    }
   ],
   "source": [
    "start_time3 = datetime.now()\n",
    "\n",
    "drop_prior_merge=\"\"\" DROP TABLE IF EXISTS prioralldata;\"\"\"\n",
    "conn.execute(drop_prior_merge)\n",
    "join_prioralldata_sql = \"\"\"\\\n",
    "    CREATE TABLE prioralldata AS\n",
    "    SELECT o.*, gd.product_name, gd.department, gd.aisle\n",
    "    FROM orderscombined1 o\n",
    "    INNER JOIN productscombined gd\n",
    "    ON o.product_id = gd.product_id;\n",
    "    \"\"\"\n",
    "conn.execute(join_prioralldata_sql)\n",
    "priorall_qc = pd.read_sql_query(\"SELECT * FROM prioralldata LIMIT 5;\", conn)\n",
    "\n",
    "# create indexes\n",
    "indexcolumns = [col for col in orderscombined1.columns if col.find(\"_id\") > -1]\n",
    "for col in indexcolumns:\n",
    "    createindexes = \"CREATE INDEX index_%s on prioralldata (%s);\" %(col + \"_prioralldata\", col)\n",
    "    conn.execute(createindexes)\n",
    "        \n",
    "end_time3 = datetime.now()\n",
    "print('\\nTime for prioralldata table: {}\\n'.format((end_time3-start_time3).total_seconds()))\n",
    "print(\"Prioralldata table: \\n\", priorall_qc.head())\n",
    "count_prior = pd.read_sql_query(\"SELECT COUNT (order_id) FROM prioralldata;\", conn)\n",
    "print(\"\\nCount orders prior table:\\n\",count_prior)\n",
    "\n",
    "# delete all temporary QC outputs\n",
    "del priorall_qc, count_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T14:36:25.136268Z",
     "start_time": "2019-08-05T14:36:24.193258Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for trainalldata table: 0.899237\n",
      "\n",
      "Trainalldata table: \n",
      "      index  order_id  user_id eval_set  order_number  order_dow  \\\n",
      "0  4344949        96    17227    train             7          6   \n",
      "1  4344949        96    17227    train             7          6   \n",
      "2  4344949        96    17227    train             7          6   \n",
      "3  4344949        96    17227    train             7          6   \n",
      "4  4344949        96    17227    train             7          6   \n",
      "\n",
      "   order_hour_of_day  days_since_prior_order  product_id  add_to_cart_order  \\\n",
      "0                 20                    30.0       20574                  1   \n",
      "1                 20                    30.0       30391                  2   \n",
      "2                 20                    30.0       40706                  3   \n",
      "3                 20                    30.0       25610                  4   \n",
      "4                 20                    30.0       27966                  5   \n",
      "\n",
      "   reordered                 product_name department  \\\n",
      "0          1               Roasted Turkey       deli   \n",
      "1          0             Organic Cucumber    produce   \n",
      "2          1       Organic Grape Tomatoes    produce   \n",
      "3          0  Organic Pomegranate Kernels     frozen   \n",
      "4          1          Organic Raspberries    produce   \n",
      "\n",
      "                        aisle  \n",
      "0                  lunch meat  \n",
      "1            fresh vegetables  \n",
      "2  packaged vegetables fruits  \n",
      "3              frozen produce  \n",
      "4  packaged vegetables fruits  \n",
      "\n",
      "Count orders train table:\n",
      "    count\n",
      "0  73575\n"
     ]
    }
   ],
   "source": [
    "start_time3 = datetime.now()\n",
    "\n",
    "drop_prior_merge=\"\"\" DROP TABLE IF EXISTS trainalldata;\"\"\"\n",
    "conn.execute(drop_prior_merge)\n",
    "join_trainalldata_sql = \"\"\"\\\n",
    "    CREATE TABLE trainalldata AS\n",
    "    SELECT o.*, gd.product_name, gd.department, gd.aisle\n",
    "    FROM orderscombined2 o\n",
    "    INNER JOIN productscombined gd\n",
    "    ON o.product_id = gd.product_id;\n",
    "    \"\"\"\n",
    "conn.execute(join_trainalldata_sql)\n",
    "trainall_qc = pd.read_sql_query(\"SELECT * FROM trainalldata LIMIT 5;\", conn)\n",
    "\n",
    "# create indexes\n",
    "indexcolumns = [col for col in orderscombined2.columns if col.find(\"_id\") > -1]\n",
    "for col in indexcolumns:\n",
    "    createindexes=\"CREATE INDEX index_%s on trainalldata (%s);\" %(col+\"_trainalldata\", col)\n",
    "    conn.execute(createindexes)        \n",
    "        \n",
    "end_time3 = datetime.now()\n",
    "print('\\nTime for trainalldata table: {}\\n'.format((end_time3-start_time3).total_seconds()))\n",
    "print(\"Trainalldata table: \\n\", trainall_qc.head())\n",
    "\n",
    "count_train = pd.read_sql_query(\"SELECT COUNT (order_id) FROM trainalldata ;\", conn)\n",
    "print(\"\\nCount orders train table:\\n\",count_train)\n",
    "\n",
    "# delete all temporary QC outputs\n",
    "del trainall_qc, count_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
